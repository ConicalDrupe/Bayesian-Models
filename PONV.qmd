
# Overview
PONV = post-operative nausea and vomiting
From a meta analysis of several studies we have rates: \
Nausea 37% \
Vomiting 20% \
for patients undergoing anesthesia.

Main and well understood risk factors are:
- Gender (0-male, 1-female)
- history of motion sickness/PONV (True/False, Sinclair Score respectively)
- Smoking status (0/1)
- Duration of anesthesia

# Q1
Use normal noninformative priors on the beta coefficents and gamma prior on the precision parameter (recipricol of variance)

## Get the Data
```{python}
import os
import pandas as pd

data_dir = os.path.join(os.getcwd(),'data','PONV.csv')
df = pd.read_csv(data_dir)

pd.options.display.max_rows = None
pd.options.display.max_columns= None

print(df.head())
print(df.columns)

data = df[['SinclairScore','Gender','Anaesthesiaduration','Smoking','PONVhist']]
data = data.rename(columns={'SinclairScore':'Sinclair','Gender':'g','Anaesthesiaduration':'ad','Smoking':'s','PONVhist':'h'})
print(data.columns)
print(data.shape)
```


## EDA
See: https://bambinos.github.io/bambi/notebooks/ESCS_multiple_regression.html

## Heiarchy Model using Non-Informative Priors
- Non-Informative meaning Priors have a large variance, so possible values are quite broad. Letting the data speak...
- Normal for Betas
- Gamma for precision (recipricol of variance)

```{python}
import pymc as pm
import matplotlib.pyplot as plt
import arviz as az

y = data['Sinclair']
X_raw = data.loc[:,data.columns != 'Sinclair']
X_raw['intercept'] = 1

shape = X_raw.shape[1] # number of beta coefficients

with pm.Model() as model:
    # Create data container for later use
    X = pm.Data("X",X_raw)

    # Hyperprior on tau (precision of beta coefficients)
    tau = pm.Gamma('tau', alpha=0.2, beta=0.2)  # a, b for Gamma prior are hyperparameters
    # Hierarchical prior on beta coefficients
    beta = pm.Normal('beta', mu=0, tau=tau, shape=shape)

    # Linear model
    mu = pm.math.dot(X, beta)

    # Likelihood of the data
    y_obs = pm.Normal('y_obs', mu=mu,tau=tau, observed=y)

    # Inference
    trace = pm.sample(2000, tune=1000)
    ppc = pm.sample_posterior_predictive(trace)

# Analyzing results
print(X_raw.columns)
print(pm.summary(trace))

```

### Output
            mean     sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \
beta[0]    0.095  0.007    0.082    0.107      0.000    0.000    5878.0   
beta[1]    0.002  0.000    0.002    0.002      0.000    0.000    6041.0   
beta[2]    0.004  0.005   -0.006    0.013      0.000    0.000    7539.0   
beta[3]   -0.029  0.006   -0.041   -0.019      0.000    0.000    7441.0   
beta[4]   -0.065  0.010   -0.085   -0.046      0.000    0.000    4615.0   
tau      205.822  9.509  188.492  224.546      0.105    0.074    8215.0   

         ess_tail  r_hat  
beta[0]    5249.0    1.0  
beta[1]    5468.0    1.0  
beta[2]    5509.0    1.0  
beta[3]    5191.0    1.0  
beta[4]    5139.0    1.0



# Q1 a. Solution
The Anesthesia Duration 95% HDI is [0.002,0.002], which represents a point density at 0.002.
This credible set does not contain 0, which means that anesthesia duration has an effect on PONV. In particular, there is a positive coorelation between Anesthesia duration and Sinclair Score.

# Q1 b. Solution

## Sinclair Score for New Data
```{python}
import numpy as np
# Define the new data point for prediction
new_data = np.array([[1,55,0,1,1]])

with model:
    pm.set_data({"X":new_data})
    # Generate posterior predictive samples for the new data
    posterior_predictive = pm.sample_posterior_predictive(trace) #,var_names=['y_obs'])

predictions = posterior_predictive['posterior_predictive']['y_obs']

# Calculate the 95% credible interval
lower_bound, upper_bound = np.percentile(predictions, [2.5, 97.5])
print(f"95% credible interval for SinclairScore: ({lower_bound:.2f}, {upper_bound:.2f})")
```

# Q1 c. Solution

## R2 Score
```{python}
y_pred = ppc.posterior_predictive.stack(sample=("chain", "draw"))["y_obs"].values.T
print(az.r2_score(y.to_numpy(), y_pred))

plt.figure()
az.plot_trace(trace, figsize=(10, 7));
plt.show()
```
